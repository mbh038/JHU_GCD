my_pois<-replicate(100,rpois(5,10))
my_pois
cm<-colmeans(my_pois)
cm<-colMeans(my_pois)
hist(cm)
dl<-Sys.Date()
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time())
t2<-as.POSIXlt(Sys.time())
class(t2)
unclass(t2)
t2
unclass(t2)
str(unclass(t2)
)
t2$min
weekdays(t1)
weekdays(d1)
months(t1)
quarters(t2)
t3<-"October 17,1986 08:24"
t3<-"October 17,1986, 08:24"
t3<-"October 17, 1986 08:24"
t4<-strptime(t3,"%B,%d,%Y %H;%M")
t4<-strptime(t3,"%B %d,%Y %H;%M")
t4<-strptime(t3,"%B %d,%Y %H:%M")
t4<-strptime(t3, "%B %d, %Y %H:%M")
print(t4)
t4
class(t4)
Sys.time()>t1
Sys.time(0-t1)
Sys.time()-t1
difftime(Sys.time(),t1,units='days')
data(cars)
help(cars)
head(cars)
plot(cars)
?plot
plot(x=cars$speed,y=cars$dist)
plot(x=cars$dist,y=cars$speed)
plot(x=cars$speed,y=cars$dist)
plot(x=cars$speed,y=cars$dist,Xlab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(cars,Title="My Plot")
plot(cars,main="My Plot")
play()
?plot
nxt()
plot(cars,sub="My Plot Subtitle")
asa
plot(cars)
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2)
data(mtcars)
play()
dim(mtcars)
str(mtcars)
summary(mtcars)
names(mtcars)
class(mtcars)
nxt()
?boxplot
boxplot(mpg~cyl,data=mtcars)
hist(mtcars$mpg)
f<-function(x){}
my.vec<-c(NA,0,2,3,4,NA)
min(my.vec)
setwd("H:/Rspace/JHU_Data_Science/JHU_GCD/Week1")
http://www.epa.gov/ttn/airs/airsaqs/detaildata/501files/RD_501_88101_2008.zip
##install and load required packages, if necessary
install.packages(xlsx)
install.packages(XML)
install.packages(data.table)
library(xlsx)
library(XML)
library(data.table)
##Set working directory
#to whichever directory has "data" as a sub-directory
##Answers to GCD, Quiz One
#create sub-directory of the working dir called "data" if one does not exist already
if(!file.exists("data")){
dir.create("data")
}
##Question One
#download data if not yet already done so
if(!file.exists("./data/Idahohousing.csv")){
#download a data file as csv in the "data" dir
#on Mac, need method="curl" if url starts with https:
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileURL,destfile="./data/idahohousing.csv")
#include date of download
datedownloaded<-date()
datedownloaded
}
#download code file if not already done so
if(!file.exists("./data/idahohousing_code.pdf")){
#- note set mode to "wb" since it is a pdf
codefileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(codefileURL,destfile="./data/idahohousing_code.pdf",mode="wb")
#list.files("./data")
#include date of download
datedownloaded<-date()
datedownloaded
}
#read csv file into dataframe
IdahoData<-read.csv("./data/idahohousing.csv")
# code fles say house value are in column "VAL", which contains integers `1-24
# In that column, value=24=> value exceeds $1,000,000
#look at this column - code book says is integers 1-24
#str(IdahoData$VAL)
# lots of NAs!
#This will return how many houses are worth more than $1m.
#deals with the NAs
q1<-sum(IdahoData$VAL==24,na.rm=TRUE)
q1.answer<-paste("Answer to Question One is",q1,sep=" ")
q1.answer
## Question Three
if(!file.exists("./data/ngap.xlsx")){
#note that mode is set to "wb" for excel files becuase they are binary files.
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileURL,destfile="./data/ngap.xlsx",mode="wb")
#list.files("./data")
datedownloaded<-date()
datedownloaded
}
ngap<-read.xlsx("./data/ngap.xlsx",sheetIndex=1,header=TRUE)
#head(ngap)
#reading specific rows and columns
colIndex<-7:15
rowIndex<-18:23
dat<-read.xlsx("./data/ngap.xlsx",sheetIndex=1,colIndex=colIndex,
rowIndex=rowIndex)
dat
q3<-sum(dat$Zip*dat$Ext,na.rm=T)
q3.answer<-paste("Answer to Question Two is",q3,sep=" ")
q3.answer
##Question Four
if(!file.exists("./data/rest.xml")){
#read xml file into a document
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileURL,destfile="./data/rest.xml")
}
doc<-xmlTreeParse("./data/rest.xml",useInternal=TRUE)
#get the root node = "wrapper" for whole document
rootNode<-xmlRoot(doc)
#parse document for zipcodes
zipcodes<-xpathSApply(rootNode,"//zipcode",xmlValue)
#str(zipcodes)
q4<-sum(zipcodes==21231)
q4.answer<-paste("Answer to Question Four is",q4,sep=" ")
q4.answer
##Question Five
#download data if not yet already done so
if(!file.exists("./data/Idaho2006.csv")){
#download a data file as csv in the "data" dir
#on Mac, need method="curl" if url starts with https:
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL,destfile="./data/Idaho2006.csv")
#include date of download
datedownloaded<-date()
datedownloaded
}
DT<-fread("./data/Idaho2006.csv")
#works
a1<-tapply(DT$pwgtp15,DT$SEX,mean)
a1
t1<-system.time(
for(i in 1:1000){
a1<-tapply(DT$pwgtp15,DT$SEX,mean)
}
)
t1
#does not work
#a2<-rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
#a2
#t2<-system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
#t2
#works
a3<-sapply(split(DT$pwgtp15,DT$SEX),mean)
a3
t3<-system.time(
for(i in 1:1000){
a3<-sapply(split(DT$pwgtp15,DT$SEX),mean)
}
)
t3
#does not calculate two means
#a4<-mean(DT$pwgtp15,by=DT$SEX)
#a4
#t4<-system.time(mean(DT$pwgtp15,by=DT$SEX))
#t4
#works
a5<-mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
a5
t5<-system.time(
for(i in 1:1000){
a5<-mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
}
)
t5
#works
a6<-DT[,mean(pwgtp15),by=SEX]
a6
t6<-system.time(
for(i in 1:1000){
a6<-DT[,mean(pwgtp15),by=SEX]
}
)
calc.times<-data.frame(c("t1","t3","t5","t6"),c(t1[1],t3[1],t5[1],t6[1])
,c(t1[2],t3[2],t5[2],t6[2]))
names(calc.times)<-c("method","user.time","elapsed.time")
arrange(calc.times,user.time)
print(paste("The fasted method is",arrange(calc.times,user.time)[1,1],sep=" "))
library("dplyr", lib.loc="\\cam-stf-fs1/users/michael.hunt/my documents/R/win-library/3.1")
calc.times<-data.frame(c("t1","t3","t5","t6"),c(t1[1],t3[1],t5[1],t6[1])
,c(t1[2],t3[2],t5[2],t6[2]))
names(calc.times)<-c("method","user.time","elapsed.time")
arrange(calc.times,user.time)
print(paste("The fasted method is",arrange(calc.times,user.time)[1,1],sep=" "))
library(dplyr)
calc.times<-data.frame(c("t1","t3","t5","t6"),c(t1[1],t3[1],t5[1],t6[1])
,c(t1[2],t3[2],t5[2],t6[2]))
names(calc.times)<-c("method","user.time","elapsed.time")
arrange(calc.times,user.time)
print(paste("The fasted method is",arrange(calc.times,user.time)[1,1],sep=" "))
2.7*8000*25
et<-2.7*8000*25
et
elec_t<-2.7*8000*25
heat_t<-0.5*8000*25
emissions<-28450
intensity<-emissions/(elec_t+heat_t)
intensity
gas.intensity<0.185
elec.intensity<-0.494
#total heat and power over project lifetime
elec.total<-2.7*8000*25
heat.total<-0.5*8000*25
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
gas.intensity<-0.185
elec.intensity<-0.494
#total heat and power over project lifetime
elec.total<-2.7*8000*25
heat.total<-0.5*8000*25
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
gas.intensity<-0.185
elec.intensity<-0.494
geo.lifetime<-25
geo.cost<3e7
#total heat and power over project lifetime
elec.total<-2.7*8000*geo.lifetime
heat.total<-0.5*8000*geo.lifetime
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
annual.saving<-carbon.saving/geo.lifetime
annual.saving
cost.kWh<-0.001*geo.cost/(elec.total+heat.total)
cost.kWh
#
gas.intensity<-0.185
elec.intensity<-0.494
geo.lifetime<-25
geo.cost<-3e7
#total heat and power over project lifetime
elec.total<-2.7*8000*geo.lifetime
heat.total<-0.5*8000*geo.lifetime
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
annual.saving<-carbon.saving/geo.lifetime
annual.saving
cost.kWh<-0.001*geo.cost/(elec.total+heat.total)
cost.kWh
#
elec.net<-2.5 #MW
heat.exp<-0.5 #MW
gas.intensity<-0.185
elec.intensity<-0.494
geo.lifetime<-25
geo.cost<-6e7
#total heat and power over project lifetime
elec.total<-elec.net*8000*geo.lifetime
heat.total<-heat.exp*8000*geo.lifetime
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
annual.saving<-carbon.saving/geo.lifetime
annual.saving
cost.kWh<-0.001*geo.cost/(elec.total+heat.total)
cost.kWh
#
elec.net<-2.5 #MW
heat.exp<-0 #MW
gas.intensity<-0.185
elec.intensity<-0.494
geo.lifetime<-25
geo.cost<-6e7
#total heat and power over project lifetime
elec.total<-elec.net*8000*geo.lifetime
heat.total<-heat.exp*8000*geo.lifetime
#total emissions
geo.emissions<-28450
geo.intensity<-geo.emissions/(elec.total+heat.total)
geo.intensity
#project emissions savings
bau.emissions<-elec.total*elec.intensity+heat.total*gas.intensity
#carbon savings
carbon.saving<-bau.emissions-geo.emissions
carbon.saving
annual.saving<-carbon.saving/geo.lifetime
annual.saving
cost.kWh<-0.001*geo.cost/(elec.total+heat.total)
cost.kWh
library("swirl", lib.loc="\\cam-stf-fs1/users/michael.hunt/my documents/R/win-library/3.1")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
ls()
rm(list=ls())
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv,stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageversion(dplyr)
packageVersion(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
select(cran,!is.na(r_version))
select(cran,!is.na(r_version)==TRUE)
select(cran,!is.na(r_version)=="TRUE")
filter(cran,!is.na(r_version)=="TRUE")
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,siz_gb=size_mb/2^10)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size-1000)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
swirl()
library(lubridate)
install.packages(lubridate)
install.packages("lubridate")
r
install.packages(xlsx)
install.packages("xlsx")
install.packages("lubridate")
install.packages("memoise")
install.packages("lubridate")
ymd("20140108")
swirl()
library(dlyr)
library(dplyr)
cran<-tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package<-group_by(cran,package)
by_package
summarize(cran,mean(size))
summarize(by_package,mean(size))
?n
?n_distinct
submit()
submit()
?summarize
n()
play()
pack_sum<-summarize(by_package,n())
pack_sum
pack_sum<-summarize(by_package,count=n())
pack_sum
pack_sum<-summarize(by_package,count=n(),unique=n_distinct(ip_id))
pack_sum
pack_sum<-summarize(by_package,count=n(),unique=n_distinct(ip_id),countries=n_distinct(country))
pack_sum
pack_sum<-summarize(by_package,count=n(),unique=n_distinct(ip_id),countries=n_distinct(country),avg_bytes=mean(size))
pack_sum
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
)
pack_sum
rm(pack_sum)
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
)
pack_sum
nxt()
submit()
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
)
source('H:/Rspace/JHU_Data_Science/JHU_GCD/Swirl/summarize1.R')
submit()
reset()
submit()
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum,unique>465)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
rm(list=ls())
install.packages(lubridate)
install.packages("lubridate")
